# Spleeter

[![Github Actions](https://github.com/deezer/spleeter/actions/workflows/python-package.yml/badge.svg)](https://github.com/deezer/spleeter/actions/workflows/python-package.yml)
[![PyPI](https://img.shields.io/pypi/v/spleeter.svg?style=flat-square)](https://pypi.org/project/spleeter/)
![Python Version](https://img.shields.io/pypi/pyversions/spleeter.svg?style=flat-square)
[![Conda](https://img.shields.io/conda/v/conda-forge/spleeter?style=flat-square)](https://anaconda.org/conda-forge/spleeter)
[![Docker Pulls](https://img.shields.io/docker/pulls/deezer/spleeter.svg?style=flat-square)](https://hub.docker.com/r/deezer/spleeter)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deezer/spleeter/blob/master/spleeter.ipynb)
[![Gitter chat status](https://img.shields.io/gitter/room/deezer/spleeter.svg?style=flat-square)](https://gitter.im/deezer/spleeter)

> [!WARNING]
> **Spleeter 2.1.0 release introduces some breaking changes**, including new CLI option naming for input, and the drop of dedicated GPU package. Please read [CHANGELOG](https://github.com/deezer/spleeter/blob/master/CHANGELOG.md) for more details.

## About

Spleeter is Deezer's source separation library with pretrained models written in Python and uses Tensorflow. It makes it easy to train source separation models (assuming you have a dataset of isolated sources), and provides already trained state-of-the-art models for performing various flavours of separation:

*   Vocals (singing voice) / accompaniment separation (2 stems)
*   Vocals / drums / bass / other separation (4 stems)
*   Vocals / drums / bass / piano / other separation (5 stems)

2 stems and 4 stems models have high performances on the musdb dataset. Spleeter is also very fast as it can perform separation of audio files to 4 stems 100x faster than real-time when run on a GPU.

We designed Spleeter so you can use it straight from the command line as well as directly in your own development pipeline as a Python library. It can be installed with pip or be used with Docker.

## Projects and Softwares using Spleeter

Since it's been released, there are multiple forks exposing Spleeter through either a Guided User Interface (GUI) or a standalone free or paying website. Please note that we do not host, maintain or directly support any of these initiatives.

That being said, many cool projects have been built on top of ours. Notably the porting to the Ableton Live ecosystem through the [Spleeter 4 Max](https://github.com/leoasm/spleeter4max) project.

Spleeter pre-trained models have also been used by professional audio softwares. Here's a non-exhaustive list:

*   iZotope in its Music Rebalance feature within RX 8
*   SpectralLayers in its Unmix feature in SpectralLayers 7
*   Acon Digital within Acoustica 7
*   VirtualDJ in their stem isolation feature
*   Algoriddim in their NeuralMix and djayPRO app suite

üÜï Spleeter is a baseline in the ongoing [Music Demixing Challenge](https://www.aicrowd.com/challenges/music-demixing-challenge-2021)!

## Spleeter Pro (Commercial version)

Check out our commercial version: [Spleeter Pro](LINK_TO_SPLEETER_PRO). Benefit from our expertise for precise audio separation, faster processing speeds, and dedicated professional support.

## Quick Start

Want to try it out but don't want to install anything? We have set up a Google Colab notebook you can use directly:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deezer/spleeter/blob/master/spleeter.ipynb)

Ready to install and run Spleeter locally? Here's a quick guide:

### Prerequisites: ffmpeg and libsndfile

Spleeter relies on `ffmpeg` and `libsndfile` for audio input/output processing. These libraries are *not* installed by `pip` and typically need to be installed separately via your system's package manager *before* installing Spleeter.

Here are common ways to install these dependencies:

*   **Debian/Ubuntu (Linux):**
    ```bash
    sudo apt update
    sudo apt install ffmpeg libsndfile1
    ```
*   **macOS (using Homebrew):**
    ```bash
    brew install ffmpeg libsndfile
    ```
*   **Windows:** Installing `ffmpeg` and `libsndfile` on Windows usually involves downloading pre-built binaries and adding their location to your system's PATH. Please refer to the official documentation for [ffmpeg](https://ffmpeg.org/download.html) and search for `libsndfile` Windows installation instructions online.

> [!NOTE]
> The previous recommendation was to use Conda for dependencies (`conda install -c conda-forge ffmpeg libsndfile`). While this *might* still work for some users, **we no longer recommend using Conda for installing spleeter and its dependencies** due to potential environment conflicts.

### Installation

Once `ffmpeg` and `libsndfile` are accessible on your system (check by running `ffmpeg -version` and `libsndfile -version` in your terminal), you can install Spleeter using pip:

```bash
pip install spleeter
Use code with caution.
Markdown
Running Separation
Download an example audio file:
# If you don't have wget, you can use curl or download it manually
wget https://github.com/deezer/spleeter/raw/master/audio_example.mp3
# Alternative with curl:
# curl -O https://github.com/deezer/spleeter/raw/master/audio_example.mp3
Use code with caution.
Bash
Separate the example audio into two components (vocals and accompaniment):
spleeter separate -p spleeter:2stems -o output audio_example.mp3
Use code with caution.
Bash
[!NOTE]
Windows Users: If the spleeter command doesn't work directly after installation, try running it using python -m spleeter instead:
python -m spleeter separate -p spleeter:2stems -o output audio_example.mp3
Use code with caution.
Bash
You should find two separated audio files (vocals.wav and accompaniment.wav) inside a new folder named output/audio_example.
[!WARNING]
There are known issues with Apple M1 chips, mostly due to TensorFlow compatibility. Until these are fixed, please refer to the Troubleshooting section in the wiki for a workaround.
For more detailed documentation on installation, usage, and available models, please check the repository wiki.
Development and Testing
This project is managed using Poetry. To set up a development environment and run the test suite, execute the following commands:
Clone spleeter repository:
git clone https://github.com/Deezer/spleeter && cd spleeter
Use code with caution.
Bash
Install poetry:
pip install poetry
Use code with caution.
Bash
Install spleeter dependencies using Poetry:
poetry install
Use code with caution.
Bash
Run unit test suite:
poetry run pytest tests/
Use code with caution.
Bash
Reference
Deezer Research - Source Separation Engine Story - deezer.io blog post (English)
Deezer Research - Source Separation Engine Story - deezer.io blog post (Japanese)
Music Source Separation tool with pre-trained models / ISMIR2019 extended abstract
If you use Spleeter in your work, please cite:
@article{spleeter2020,
  doi = {10.21105/joss.02154},
  url = {https://doi.org/10.21105/joss.02154},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {50},
  pages = {2154},
  author = {Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam},
  title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},
  journal = {Journal of Open Source Software},
  note = {Deezer Research}
}
Use code with caution.
Bibtex
License
The code of Spleeter is MIT-licensed.
Disclaimer
If you plan to use Spleeter on copyrighted material, make sure you get proper authorization from right owners beforehand.
Troubleshooting
Spleeter is a complex piece of software and although we continuously try to improve and test it you may encounter unexpected issues running it. If that's the case please check the FAQ page first as well as the list of currently open issues.
(Note: The specific mention for Windows users regarding the command shortcut has been integrated into the Quick Start section.)
Contributing
If you would like to participate in the development of Spleeter you are more than welcome to do so. Don't hesitate to throw us a pull request and we'll do our best to examine it quickly. Please check out our guidelines first.
Audio Example Source
This repository includes a demo audio file audio_example.mp3 which is an excerpt from Slow Motion Dream by Steven M Bryant (c) copyright 2011 Licensed under a Creative Commons Attribution (3.0) license Ft: CSoul, Alex Beroza & Robert Siekawitch.


2. Getting started
Romain Hennequin edited this page on Apr 2, 2021 ¬∑ 22 revisions
Usage
Separate sources
Using 2stems model
Using 4stems model
Using 5stems model
Using models up to 16kHz
Batch processing
Exported filename format
Train model
Evaluate model
Using Docker image
Available images
Run container
Usage
Once installed, Spleeter can be used directly from any CLI through the spleeter command. It provides three action with following subcommand :

Command	Description
separate	Separate audio files using pretrained model
train	Train a source separation model. You need a dataset of separated tracks to use it
evaluate	Pretrained model evaluation over musDB test set
Separate sources
To get help on the different options available with the separate command, type:

spleeter separate --help
If you are using the GPU version and want to specify the device card number, you'll need to set the CUDA_VISIBLE_DEVICES variable.

Using 2stems model
You can straightforwardly separate audio files with the default 2 stems (vocals / accompaniment) pretrained model like following1 :

spleeter separate -o audio_output audio_example.mp3 
1 be sure to be in the spleeter folder if you are using cloned repository or replace audio_example.mp3 by a valid path to an audio file).

You can provide either a single or a list of files as argument (even using wildcard patterns if supported by your shell). The -o is for providing the output path where to write the separated wav files. The command may take quite some time to execute at first run, since it will download the pre-trained model. If everything goes well, you should then get a folder audio_output/audio_example that contains two files: accompaniment.wav and vocals.wav.

‚ö†Ô∏è In versions prior to 2.1 files were passed with the -i option but it's no longer the case

Using 4stems model
You can also use a pretrained 4 stems (vocals / bass / drums / other ) model :

spleeter separate -o audio_output -p spleeter:4stems audio_example.mp3
The -p option is for providing the model settings. It could be either a Spleeter embedded setting identifier2 or a path to a JSON file configuration such as this one.

This time, it will generate four files: vocals.wav, drums.wav, bass.wav and other.wav.

2 at this time, following embedded configuration are available :

spleeter:2stems
spleeter:4stems
spleeter:5stems
Using 5stems model
Finally a pretrained 5 stems (vocals / bass / drums / piano / other) model is also available out of the box :

spleeter separate -o audio_output -p spleeter:5stems audio_example.mp3
Which would generate five files: vocals.wav, drums.wav, bass.wav, piano.wav and other.wav.

Using models up to 16kHz
All the previous models (spleeter:2stems, spleeter:4stems and spleeter:5stems) performs separation up to 11kHz. There also exists 16kHz versions of the same models (resp. (spleeter:2stems-16kHz, spleeter:4stems-16kHz and spleeter:5stems-16kHz)). They can be used the same way:

spleeter separate -o audio_output -p spleeter:4stems-16kHz audio_example.mp3 
For more details read this FAQ.

Batch processing
separate command builds the model each time it is called and downloads it the first time. This process may be long compared to the separation process by itself if you process a single audio file (especially a short one). If you have several files to separate, it is then recommended to perform all separation with a single call to separate:

spleeter separate \
     -o audio_output \
     <path/to/audio1.mp3> <path/to/audio2.wav> <path/to/audio3.ogg> 
Exported filename format
the -f option makes it possible to format the name and folder of the output audio files. The following keyword can be used:

filename: input file name (without extension).
instrument: name of the separated instrument
foldername: name of the folder the input file is in
codec: extension of the output audio files.
They should be used between curly brackets within the formatting string.

For instance:

spleeter separate \
     -o audio_output \
     /path/to/audio_folder/song.mp3 \
     -f {foldername}/{filename}_{instrument}.{codec}
will output the following files audio_output/audio_folder/song_vocals.wav and audio_output/audio_folder/song_accompaniment.wav

Train model
For training your own model, you need:

A dataset of separated files such as musDB.
Dataset must be described in CSV files : one for training and one for validation) which are used for generating training data.
A JSON configuration file such as this one that gathers all parameters needed for training and paths to CSV file.
Once your train configuration is setup, you can run model training as following :

spleeter train -p configs/musdb_config.json -d </path/to/musdb>
Evaluate model
For evaluating a model, you need the musDB dataset. You can for instance evaluate the provided 4 stems pre-trained model this way:

spleeter evaluate -p spleeter:4stems --mus_dir </path/to/musdb> -o eval_output
For using multi-channel Wiener filtering for performing the separation, you need to add the --mwf option (to get the results reported in the paper):

spleeter evaluate -p spleeter:4stems --mus_dir </path/to/musdb> -o eval_output --mwf
Using Docker image
Docker Pulls

We are providing official Docker images for using Spleeter. You need first to install Docker, for instance the Docker Community Edition.

Available images
To be documented

Run container
Built images entrypoint is Spleeter main command spleeter. Thus you can run the separate command by running this previously built image using docker run3 command with a mounted directory for output writing :

docker run -v $(pwd)/output:/output deezer/spleeter separate -o /output audio_example.mp3
If you want to run the image with GPU device support you can use the dedicated GPU image :

# If you have nvidia-docker:
nvidia-docker run -v $(pwd)/output:/output deezer/spleeter-gpu separate -o /output audio_example.mp3

# Or if your docker client version is high enough to support `Nvidia` runtime :
docker run --runtime=nvidia -v $(pwd)/output:/output deezer/spleeter-gpu separate -o /output audio_example.mp3
3 For running command over GPU, you should use nvidia-docker command instead of docker command. This alternative command allows container to access Nvidia driver and the GPU devices from host.

This will separate the audio file provided as input (here audio_example.mp3 which is embedded in the built image) and put the separated files vocals.wav and accompaniment.wav on your computer in the mounted output folder output/audio_example.

For using your own audio file you will need to create container volume when running the image, we also suggest you to create a volume for storing downloaded model. This will avoid Spleeter to download model files each time you run the image.

To do so let's first create some environment variable :

export AUDIO_IN='/path/to/directory/with/audio/file'
export AUDIO_OUT='/path/to/write/separated/source/into'
export MODEL_DIRECTORY='/path/to/model/storage'
Then we can run the separate command through container :

docker run \
    -v $AUDIO_IN:/input \
    -v $AUDIO_OUT:/output \
    -v $MODEL_DIRECTORY:/model \
    -e MODEL_PATH=/model \
    deezer/spleeter \
    separate -o /output /input/audio_1.mp3 /input/audio_2.mp3
‚ö†Ô∏è As for non docker usage we recommend you to perform separation of multiple file with a single call on Spleeter image.

You can use the train command (that you should mainly use with a GPU as it is very computationally expensive), as well as the evaluate command, that performs evaluation on the musDB test dataset4 using museval

# Model training.
nvidia-docker run -v </path/to/musdb>:/musdb deezer/spleeter-gpu train -p configs/musdb_config.json -d /musdb

# Model evaluation.
nvidia-docker run -v $(pwd)/eval_output:/eval_output -v </path/to/musdb>:/musdb deezer/spleeter-gpu evaluate -p spleeter:4stems --mus_dir /musdb -o /eval_output
4 You need to request access and download it from here

The separation process should be quite fast on a GPU (should be less than 90s on the musdb test set) but the execution of museval takes much more time (a few hours).

¬© Deezer